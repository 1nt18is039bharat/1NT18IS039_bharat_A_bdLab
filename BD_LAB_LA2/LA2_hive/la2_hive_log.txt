hdoop@ubuntu:~$ ls
apache-hive-3.1.2-bin  Downloads            hs_err_pid29507.log  snap
bank                   eclipse-workspace    hs_err_pid32715.log  Templates
derby.log              examples.desktop     metastore_db         tmpdata
Desktop                hadoop-3.2.1         Music                Videos
dfsdata                hs_err_pid21913.log  Pictures
Documents              hs_err_pid29299.log  Public
hdoop@ubuntu:~$ cd apache-hive-3.1.2-bin
hdoop@ubuntu:~/apache-hive-3.1.2-bin$ cd bin
hdoop@ubuntu:~/apache-hive-3.1.2-bin/bin$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/hdoop/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hdoop/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 446de849-0312-4e9e-a605-c009a659b297

Logging initialized using configuration in jar:file:/home/hdoop/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
Hive Session ID = 4b847042-4a67-488b-8d1b-f685044c70fe
hive> show databases;
OK
customer
default
employee
Time taken: 0.719 seconds, Fetched: 3 row(s)
hive> create database employeeDB;
OK
Time taken: 0.298 seconds
hive> show databases;
OK
customer
default
employee
employeedb
Time taken: 0.028 seconds, Fetched: 4 row(s)
hive> create table employee(
    > empname string,
    > ssn int,
    > salary float,
    > address string,
    > department string,
    > exp int)
    > row format delimited fields terminated by ",";
OK
Time taken: 1.606 seconds
hive> desc employee;
OK
empname             	string              	                    
ssn                 	int                 	                    
salary              	float               	                    
address             	string              	                    
department          	string              	                    
exp                 	int                 	                    
Time taken: 0.409 seconds, Fetched: 6 row(s)
hive> LOAD DATA LOCAL INPATH '/home/hdoop/Documents/LA2.csv' INTO TABLE EMPLOYEE;
Loading data to table default.employee
OK
Time taken: 2.488 seconds
hive> select * from employee;
OK
Bharat	5000	60000.0	Bangalore	ISE	5
Khushi	5001	55000.0	Delhi	CSE	8
Abhay	5002	26000.0	Bangalore	AE	2
Ajay	5003	30000.0	Delhi	CSE	3
Kavi	5004	48000.0	Chennai	ECE	5
Nidhi	5005	49000.0	Hyderabad	ME	7
Vijay	5006	53000.0	Mumbai	ISE	6
Nishtha	5007	78000.0	Sikkim	EE	8
Kevin	5008	20000.0	Tumkur	ECE	3
Srishti	5009	83000.0	Bangalore	ISE	5
Aditya	5010	50000.0	Bhadra	ISE	6
Ashok	5011	24000.0	Kerala	ISE	8
Anjali	5012	81000.0	Mangalore	ECE	5
Alok	5013	91000.0	Assam	CSE	3
Aditya	5014	23000.0	Gurgaon	ISE	7
Priyanka	5015	67000.0	Mumbai	ISE	5
Pooja	5016	61000.0	Bangalore	MEC	6
Yashas	5017	29000.0	Bihar	ISE	5
Mayuri	5018	71000.0	Chennai	EE	7
Rupali	5019	64000.0	Delhi	ISE	6
Time taken: 3.196 seconds, Fetched: 20 row(s)
hive> insert into table employee values
    > (5020,34000, "Bangalore", "MEC", 5),
    > (5021,34hdoop@ubuntu:~/apache-hive-3.1.2-bin/bin$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/hdoop/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hdoop/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = be04c72b-acd6-44b2-be0b-2d97678cbc70

Logging initialized using configuration in jar:file:/home/hdoop/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = 40a8340f-402a-414a-a21f-f16bf0aacf97
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> insert into table employee values
    > ("Kevinson",5020,34000, "Bangalore", "MEC", 5),
    > ("Pallavi",5021,6000, "Mangalore", "AE", 3),
    > ("Aditya",5022,56000, "Mumbai", "ISE", 8),
    > ("Alistar",5023,20000, "Bangalore", "CSE", 2),
    > ("Daksh",5024,80000, "Rajastan", "CSE", 6);
Query ID = hdoop_20210708084802_89d613f8-c148-408e-89b8-8fa444d1c4f8
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625757908444_0001, Tracking URL = http://ubuntu:8088/proxy/application_1625757908444_0001/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625757908444_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2021-07-08 08:49:11,543 Stage-1 map = 0%,  reduce = 0%
2021-07-08 08:50:06,765 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 56.32 sec
2021-07-08 08:50:14,163 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 59.85 sec
MapReduce Total cumulative CPU time: 59 seconds 850 msec
Ended Job = job_1625757908444_0001
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory hdfs://127.0.0.1:9000/user/hive/warehouse/employee/.hive-staging_hive_2021-07-08_08-48-02_544_8148482328022036104-1/-ext-10000
Loading data to table default.employee
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 59.85 sec   HDFS Read: 21781 HDFS Write: 686 SUCCESS
Total MapReduce CPU Time Spent: 59 seconds 850 msec
OK
Time taken: 136.058 seconds
hive> select * from employee;
OK
Kevinson	5020	34000.0	Bangalore	MEC	5
Pallavi	5021	6000.0	Mangalore	AE	3
Aditya	5022	56000.0	Mumbai	ISE	8
Alistar	5023	20000.0	Bangalore	CSE	2
Daksh	5024	80000.0	Rajastan	CSE	6
Bharat	5000	60000.0	Bangalore	ISE	5
Khushi	5001	55000.0	Delhi	CSE	8
Abhay	5002	26000.0	Bangalore	AE	2
Ajay	5003	30000.0	Delhi	CSE	3
Kavi	5004	48000.0	Chennai	ECE	5
Nidhi	5005	49000.0	Hyderabad	ME	7
Vijay	5006	53000.0	Mumbai	ISE	6
Nishtha	5007	78000.0	Sikkim	EE	8
Kevin	5008	20000.0	Tumkur	ECE	3
Srishti	5009	83000.0	Bangalore	ISE	5
Aditya	5010	50000.0	Bhadra	ISE	6
Ashok	5011	24000.0	Kerala	ISE	8
Anjali	5012	81000.0	Mangalore	ECE	5
Alok	5013	91000.0	Assam	CSE	3
Aditya	5014	23000.0	Gurgaon	ISE	7
Priyanka	5015	67000.0	Mumbai	ISE	5
Pooja	5016	61000.0	Bangalore	MEC	6
Yashas	5017	29000.0	Bihar	ISE	5
Mayuri	5018	71000.0	Chennai	EE	7
Rupali	5019	64000.0	Delhi	ISE	6
Time taken: 0.233 seconds, Fetched: 25 row(s)
hive> alter table employee rename to emp;
OK
Time taken: 0.472 seconds
hive> show tables;
OK
emp
Time taken: 0.044 seconds, Fetched: 1 row(s)
hive> desc emp;
OK
empname             	string              	                    
ssn                 	int                 	                    
salary              	float               	                    
address             	string              	                    
department          	string              	                    
exp                 	int                 	                    
Time taken: 0.076 seconds, Fetched: 6 row(s)
hive> select empname,ssn,salary from emp where salary>=50000;
OK
Aditya	5022	56000.0
Daksh	5024	80000.0
Bharat	5000	60000.0
Khushi	5001	55000.0
Vijay	5006	53000.0
Nishtha	5007	78000.0
Srishti	5009	83000.0
Aditya	5010	50000.0
Anjali	5012	81000.0
Alok	5013	91000.0
Priyanka	5015	67000.0
Pooja	5016	61000.0
Mayuri	5018	71000.0
Rupali	5019	64000.0
Time taken: 0.58 seconds, Fetched: 14 row(s)
hive> select empname,ssn,salary from emp where address="Bangalore" and salary<50000;
OK
Kevinson	5020	34000.0
Alistar	5023	20000.0
Abhay	5002	26000.0
Time taken: 0.326 seconds, Fetched: 3 row(s)
hive> create view emp_departmant as select empname as name, dept_name as dept_name from emp;
OK
Time taken: 0.244 seconds
hive> select * from emp_department;
FAILED: SemanticException [Error 10001]: Line 1:14 Table not found 'emp_department'
hive> select * from emp_departmant;
OK
Kevinson	MEC
Pallavi	AE
Aditya	ISE
Alistar	CSE
Daksh	CSE
Bharat	ISE
Khushi	CSE
Abhay	AE
Ajay	CSE
Kavi	ECE
Nidhi	ME
Vijay	ISE
Nishtha	EE
Kevin	ECE
Srishti	ISE
Aditya	ISE
Ashok	ISE
Anjali	ECE
Alok	CSE
Aditya	ISE
Priyanka	ISE
Pooja	MEC
Yashas	ISE
Mayuri	EE
Rupali	ISE
Time taken: 0.495 seconds, Fetched: 25 row(s)
hive> select ssn, empname from emp_details group by ssn,empname order by name;
FAILED: SemanticException [Error 10001]: Line 1:25 Table not found 'emp_details'
hive> select ssn, empname from emp group by ssn,empname order by name;
FAILED: SemanticException [Error 10004]: Line 1:72 Invalid table alias or column reference 'name': (possible column names are: ssn, empname)
hive> select ssn, empname from emp group by ssn,empname order by empname;
Query ID = hdoop_20210708090544_877a2620-6ce7-4901-9818-325ee56a168a
Total jobs = 2
Launching Job 1 out of 2
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625757908444_0002, Tracking URL = http://ubuntu:8088/proxy/application_1625757908444_0002/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625757908444_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2021-07-08 09:05:56,493 Stage-1 map = 0%,  reduce = 0%
2021-07-08 09:06:45,479 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 84.74 sec
2021-07-08 09:06:52,778 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 86.76 sec
MapReduce Total cumulative CPU time: 1 minutes 26 seconds 760 msec
Ended Job = job_1625757908444_0002
Launching Job 2 out of 2
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625757908444_0003, Tracking URL = http://ubuntu:8088/proxy/application_1625757908444_0003/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625757908444_0003
Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
2021-07-08 09:07:06,657 Stage-2 map = 0%,  reduce = 0%
2021-07-08 09:07:12,926 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.27 sec
2021-07-08 09:07:19,173 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.95 sec
MapReduce Total cumulative CPU time: 4 seconds 950 msec
Ended Job = job_1625757908444_0003
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 86.76 sec   HDFS Read: 13032 HDFS Write: 766 SUCCESS
Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.95 sec   HDFS Read: 8043 HDFS Write: 682 SUCCESS
Total MapReduce CPU Time Spent: 1 minutes 31 seconds 710 msec
OK
5002	Abhay
5010	Aditya
5014	Aditya
5022	Aditya
5003	Ajay
5023	Alistar
5013	Alok
5012	Anjali
5011	Ashok
5000	Bharat
5024	Daksh
5004	Kavi
5008	Kevin
5020	Kevinson
5001	Khushi
5018	Mayuri
5005	Nidhi
5007	Nishtha
5021	Pallavi
5016	Pooja
5015	Priyanka
5019	Rupali
5009	Srishti
5006	Vijay
5017	Yashas
Time taken: 96.763 seconds, Fetched: 25 row(s)
hive> select max(salary) as maximum_sal, min(salary) as minimum_sal, avg(salary) as average_sal from emp;
Query ID = hdoop_20210708091029_9f72f871-7b9d-4d5b-a556-79816f73a934
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625757908444_0004, Tracking URL = http://ubuntu:8088/proxy/application_1625757908444_0004/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625757908444_0004
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2021-07-08 09:10:37,707 Stage-1 map = 0%,  reduce = 0%
2021-07-08 09:10:42,885 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 1.7 sec
2021-07-08 09:10:49,088 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.54 sec
MapReduce Total cumulative CPU time: 4 seconds 540 msec
Ended Job = job_1625757908444_0004
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.54 sec   HDFS Read: 18419 HDFS Write: 122 SUCCESS
Total MapReduce CPU Time Spent: 4 seconds 540 msec
OK
91000.0	6000.0	50360.0
Time taken: 20.876 seconds, Fetched: 1 row(s)
hive> create table department(
    > Dno int,
    > Dname string)
    > row format delimited fields terminated by ",";
OK
Time taken: 0.304 seconds
hive> desc department;
OK
dno                 	int                 	                    
dname               	string              	                    
Time taken: 0.086 seconds, Fetched: 2 row(s)
hive> insert into department values(1,"ISE"),(2,"CSE"),(3,"ECE"),(4,"EEE"),(5,"AE"),(6,"MEC");
Query ID = hdoop_20210708091818_f57f967d-1a44-4b07-bdcb-13ad533567cf
Total jobs = 3
Launching Job 1 out of 3
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625757908444_0005, Tracking URL = http://ubuntu:8088/proxy/application_1625757908444_0005/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625757908444_0005
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2021-07-08 09:18:27,834 Stage-1 map = 0%,  reduce = 0%
2021-07-08 09:18:33,057 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.81 sec
2021-07-08 09:18:39,279 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 4.71 sec
MapReduce Total cumulative CPU time: 4 seconds 710 msec
Ended Job = job_1625757908444_0005
Stage-4 is selected by condition resolver.
Stage-3 is filtered out by condition resolver.
Stage-5 is filtered out by condition resolver.
Moving data to directory hdfs://127.0.0.1:9000/user/hive/warehouse/department/.hive-staging_hive_2021-07-08_09-18-18_579_1741971577422490656-1/-ext-10000
Loading data to table default.department
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 4.71 sec   HDFS Read: 15736 HDFS Write: 344 SUCCESS
Total MapReduce CPU Time Spent: 4 seconds 710 msec
OK
Time taken: 22.252 seconds
hive> select * from department;
OK
1	ISE
2	CSE
3	ECE
4	EEE
5	AE
6	MEC
Time taken: 0.179 seconds, Fetched: 6 row(s)
hive> select dno,ssn,empname from emp e full outer join department d on e.department=d.dname;
Query ID = hdoop_20210708092835_7e22e4a0-7c64-433b-b593-d958c51b19c3
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1625757908444_0008, Tracking URL = http://ubuntu:8088/proxy/application_1625757908444_0008/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625757908444_0008
Hadoop job information for Stage-1: number of mappers: 2; number of reducers: 1
2021-07-08 09:28:42,814 Stage-1 map = 0%,  reduce = 0%
2021-07-08 09:29:00,796 Stage-1 map = 50%,  reduce = 0%, Cumulative CPU 12.13 sec
2021-07-08 09:29:01,836 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 25.49 sec
2021-07-08 09:29:07,118 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 27.28 sec
MapReduce Total cumulative CPU time: 27 seconds 280 msec
Ended Job = job_1625757908444_0008
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 2  Reduce: 1   Cumulative CPU: 27.28 sec   HDFS Read: 17615 HDFS Write: 752 SUCCESS
Total MapReduce CPU Time Spent: 27 seconds 280 msec
OK
5	5002	Abhay
5	5021	Pallavi
2	5023	Alistar
2	5003	Ajay
2	5001	Khushi
2	5024	Daksh
2	5013	Alok
3	5012	Anjali
3	5004	Kavi
3	5008	Kevin
4	5007	Nishtha
4	5018	Mayuri
4	NULL	NULL
1	5019	Rupali
1	5017	Yashas
1	5015	Priyanka
1	5014	Aditya
1	5011	Ashok
1	5010	Aditya
1	5009	Srishti
1	5006	Vijay
1	5000	Bharat
1	5022	Aditya
6	5005	Nidhi
6	5020	Kevinson
6	5016	Pooja
Time taken: 33.604 seconds, Fetched: 26 row(s)
hive> select * from emp;
OK
Kevinson	5020	34000.0	Bangalore	MEC	5
Pallavi	5021	6000.0	Mangalore	AE	3
Aditya	5022	56000.0	Mumbai	ISE	8
Alistar	5023	20000.0	Bangalore	CSE	2
Daksh	5024	80000.0	Rajastan	CSE	6
Bharat	5000	60000.0	Bangalore	ISE	5
Khushi	5001	55000.0	Delhi	CSE	8
Abhay	5002	26000.0	Bangalore	AE	2
Ajay	5003	30000.0	Delhi	CSE	3
Kavi	5004	48000.0	Chennai	ECE	5
Nidhi	5005	49000.0	Hyderabad	ME	7
Vijay	5006	53000.0	Mumbai	ISE	6
Nishtha	5007	78000.0	Sikkim	EE	8
Kevin	5008	20000.0	Tumkur	ECE	3
Srishti	5009	83000.0	Bangalore	ISE	5
Aditya	5010	50000.0	Bhadra	ISE	6
Ashok	5011	24000.0	Kerala	ISE	8
Anjali	5012	81000.0	Mangalore	ECE	5
Alok	5013	91000.0	Assam	CSE	3
Aditya	5014	23000.0	Gurgaon	ISE	7
Priyanka	5015	67000.0	Mumbai	ISE	5
Pooja	5016	61000.0	Bangalore	MEC	6
Yashas	5017	29000.0	Bihar	ISE	5
Mayuri	5018	71000.0	Chennai	EE	7
Rupali	5019	64000.0	Delhi	ISE	6
Time taken: 0.113 seconds, Fetched: 25 row(s)
hive> select dno,ssn,empname from emp e left outer join department d on e.department=d.dname;
Query ID = hdoop_20210708093459_e67c25c1-670a-447e-96f6-1dc67322cab1
Total jobs = 1
SLF4J: Found binding in [jar:file:/home/hdoop/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hdoop/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

2021-07-08 09:35:13	End of local task; Time Taken: 1.399 sec.Execution completed successfully
MapredLocal task succeeded

Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1625757908444_0009, Tracking URL = http://ubuntu:8088/proxy/application_1625757908444_0009/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625757908444_0009
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
2021-07-08 09:35:23,074 Stage-3 map = 0%,  reduce = 0%
2021-07-08 09:35:29,284 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.6 sec
MapReduce Total cumulative CPU time: 2 seconds 600 msec
Ended Job = job_1625757908444_0009
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 1   Cumulative CPU: 2.6 sec   HDFS Read: 9965 HDFS Write: 732 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 600 msec
OK
6	5020	Kevinson
5	5021	Pallavi
1	5022	Aditya
2	5023	Alistar
2	5024	Daksh
1	5000	Bharat
2	5001	Khushi
5	5002	Abhay
2	5003	Ajay
3	5004	Kavi
6	5005	Nidhi
1	5006	Vijay
4	5007	Nishtha
3	5008	Kevin
1	5009	Srishti
1	5010	Aditya
1	5011	Ashok
3	5012	Anjali
2	5013	Alok
1	5014	Aditya
1	5015	Priyanka
6	5016	Pooja
1	5017	Yashas
4	5018	Mayuri
1	5019	Rupali
Time taken: 33.397 seconds, Fetched: 25 row(s)
hive> select dno,ssn,empname from emp e right outer join department d on e.department=d.dname;
Query ID = hdoop_20210708093627_c70ced6b-7b5b-4797-8d3f-31496145ffdd
Total jobs = 1
2021-07-08 09:36:34	Starting to launch local task to process map join;	maximum memory = 239075328
Execution completed successfully
MapredLocal task succeeded
Launching Job 1 out of 1
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1625757908444_0010, Tracking URL = http://ubuntu:8088/proxy/application_1625757908444_0010/
Kill Command = /home/hdoop/hadoop-3.2.1/bin/mapred job  -kill job_1625757908444_0010
Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 0
2021-07-08 09:36:46,407 Stage-3 map = 0%,  reduce = 0%
2021-07-08 09:36:51,611 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 2.38 sec
MapReduce Total cumulative CPU time: 2 seconds 380 msec
Ended Job = job_1625757908444_0010
MapReduce Jobs Launched: 
Stage-Stage-3: Map: 1   Cumulative CPU: 2.38 sec   HDFS Read: 8762 HDFS Write: 752 SUCCESS
Total MapReduce CPU Time Spent: 2 seconds 380 msec
OK
1	5022	Aditya
1	5000	Bharat
1	5006	Vijay
1	5009	Srishti
1	5010	Aditya
1	5011	Ashok
1	5014	Aditya
1	5015	Priyanka
1	5017	Yashas
1	5019	Rupali
2	5023	Alistar
2	5024	Daksh
2	5001	Khushi
2	5003	Ajay
2	5013	Alok
3	5004	Kavi
3	5008	Kevin
3	5012	Anjali
4	NULL	NULL
5	5021	Pallavi
5	5002	Abhay
6	5020	Kevinson
6	5016	Pooja
6	5005	Nidhi
4	5007	Nishtha
4	5018	Mayuri
Time taken: 26.434 seconds, Fetched: 26 row(s)
hive> 

